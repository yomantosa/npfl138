### Assignment: flow_matching
#### Date: Deadline: Jun 30, 22:00
#### Points: 3 points
#### Tests: flow_matching_tests
#### Examples: flow_matching_examples

Implement a flow matching mode based on a U-Net architecture to unconditionally
generate images with $64Ã—64$ resolution.

The unlabeled image data can be loaded using the
[image64_dataset](https://ufal.mff.cuni.cz/~straka/courses/npfl138/2425/docs/datasets/image64_dataset/)
module, with the following datasets being available:
- `oxford_flowers102`: 8k [images of flowers](https://ufal.mff.cuni.cz/~straka/courses/npfl138/2425/demos/oxford_flowers102.jpg), 67MB,
- `lsun_bedrooms`: 15k [images of bedrooms](https://ufal.mff.cuni.cz/~straka/courses/npfl138/2425/demos/lsun_bedrooms.jpg), 109MB,
- `ffhq`: 70k [images of Flickr faces](https://ufal.mff.cuni.cz/~straka/courses/npfl138/2425/demos/ffhq.jpg), 529MB.

Start with the [flow_matching.py](https://github.com/ufal/npfl138/tree/master/labs/13/flow_matching.py)
template, which contains extensive comments indicating how the architecture
should look like and how the training and sampling should be performed. Note that the
template generate images to TensorBoard (after the whole training and optionally
also each `--plot_each` epoch), and the images generated by the reference
solution can be also seen in the Examples.

To obtain the same results as in the below tests, use _lazy_ convolutional and
_lazy_ linear layers, and create all layers in the same order as mentioned in
the comments. However, in ReCodEx, any order of layer creation should pass, as
should non-lazy layers.

#### Tests Start: flow_matching_tests
_Note that your results may be slightly different, depending on your CPU type and whether you use a GPU._

1. `python3 flow_matching.py --epochs=1 --epoch_batches=16 --batch_size=8 --stages=2 --stage_blocks=2 --channels=8 --ema=0.9 --sampling_steps=8`
```
Epoch 1/1 4.7s train_loss=1.1229 sample_mean=0.4163 sample_std=0.2942
```
To make debugging easier, here are variances of the first batches of various quantities:
```
The torch.var of the first batch of noisy training images (model input): 1.0105
The torch.var of the first batch of embedded times: 0.3440
The torch.var of the first batch returned by ResidualBlock: 0.4083
The torch.var of the first batch returned by DownscalingBlock: (0.2946, 0.4083)
The torch.var of the first batch returned by UpscalingBlock: 0.3679
The torch.var of the first batch of model predictions during training: 0.8467
The torch.var of the first batch of target outputs during training: 2.4856
The torch.var of the first batch of model predictions during generate: 0.8083
```

2. `python3 flow_matching.py --epochs=1 --epoch_batches=10 --batch_size=12 --stages=3 --stage_blocks=1 --channels=12 --ema=0.8 --sampling_steps=7`
```
Epoch 1/1 6.3s train_loss=1.3070 sample_mean=0.4181 sample_std=0.3152
```
#### Tests End:
#### Examples Start: flow_matching_examples
_Note that your results may be slightly different, depending on your CPU type and whether you use a GPU._
- `python3 flow_matching.py --dataset=oxford_flowers102 --epochs=70 --plot_each=10`
![oxford_flowers102 samples](https://ufal.mff.cuni.cz/~straka/courses/npfl138/2425/demos/flow_matching-oxford_flowers102.webp)
- `python3 flow_matching.py --dataset=lsun_bedrooms --epochs=100 --plot_each=10`
![lsun_bedrooms samples](https://ufal.mff.cuni.cz/~straka/courses/npfl138/2425/demos/flow_matching-lsun_bedrooms.webp)
- `python3 flow_matching.py --dataset=ffhq --epochs=100 --stage_blocks=4 --batch_size=256 --plot_each=10`
![ffhq samples](https://ufal.mff.cuni.cz/~straka/courses/npfl138/2425/demos/flow_matching-ffhq.webp)
#### Examples End:
